# -*- coding: utf-8 -*-
"""Image Classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DEt3v9h0ZjYSnOQl-E6vdKxjz41vCUSr
"""

from tensorflow import keras
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score,confusion_matrix,classification_report
import numpy as np
import cv2
import numpy as np
import tensorflow as tf
from tensorflow.keras import layers, models
from sklearn.metrics import accuracy_score

(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()

x_train.shape,x_test.shape

# Normalization
x_train = x_train/255.0
x_test = x_test/255.0

"""# **Random Forest**"""

import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

# Flatten the image data
x_train_flatten = x_train.reshape(x_train.shape[0], -1)
x_test_flatten = x_test.reshape(x_test.shape[0], -1)

# Create and train the Random Forest classifier
rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)
rf_classifier.fit(x_train_flatten, y_train)

# Make predictions
y_pred = rf_classifier.predict(x_test_flatten)

# Calculate accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy:.4f}")

accuracy_score(y_pred,y_test)
print(classification_report(y_pred,y_test))

"""# **Implementing a Decision Tree**"""

import numpy as np
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score

# Flatten the image data
x_train_flatten = x_train.reshape(x_train.shape[0], -1)
x_test_flatten = x_test.reshape(x_test.shape[0], -1)

# Create and train the Decision Tree classifier
dt_classifier = DecisionTreeClassifier(random_state=42)
dt_classifier.fit(x_train_flatten, y_train)

# Make predictions
y_pred = dt_classifier.predict(x_test_flatten)

# Calculate accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy:.4f}")

"""# **Implementating CNN**"""

(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()

# Normalize the image data
x_train_normalized = x_train / 255.0
x_test_normalized = x_test / 255.0

# Define the CNN architecture
model = models.Sequential()
model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.Flatten())
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dense(10, activation='softmax'))

# Compile the model
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

# Set the number of epochs
epochs = 50

# Callbacks for saving model and TensorBoard logging
callbacks = [
    tf.keras.callbacks.ModelCheckpoint("save_at_{epoch}.h5"),
    tf.keras.callbacks.TensorBoard(log_dir="logs", write_graph=True, write_images=False, update_freq="epoch"),
]

# Train the model and evaluate simultaneously
history = model.fit(
    x=x_train_normalized,
    y=y_train,
    validation_data=(x_test_normalized, y_test),
    epochs=epochs,
    callbacks=callbacks
)

# Evaluate the model on the test data
test_loss, test_accuracy = model.evaluate(x_test_normalized, y_test)
print(f"Test accuracy: {test_accuracy:.4f}")

import numpy as np
# Evaluate the model on the test data
test_loss, test_accuracy = model.evaluate(x_test_normalized, y_test)
print(f"Test accuracy: {test_accuracy:.4f}")

# Predict class probabilities for the test data
probabilities = model.predict(x_test_normalized)

# Define a threshold for low probability
probability_threshold = 0.2  # Adjust this value as needed

# Generate labels based on probabilities and threshold
labels = []
for prob in probabilities:
    if np.max(prob) >= probability_threshold:
        labels.append(np.argmax(prob))
    else:
        labels.append("Image not in data label")
# Print some example results
for i in range(10):  # Print results for the first 10 images
    true_label = y_test[i]
    predicted_label = labels[i]
    print(f"True Label: {true_label}, Predicted Label: {predicted_label}")

model.save("Image_Classification_Model.h5")

# lets explore our metrics a bit
import pandas as pd
Metrics = pd.DataFrame(model.history.history)

Metrics

# Commented out IPython magic to ensure Python compatibility.
# Load the TensorBoard notebook extension
# %load_ext tensorboard
# %tensorboard --logdir logs

!pip install gradio

import gradio as gr
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import load_model
from PIL import Image

# Load your CNN model
model_path = "Image_Classification_Model.h5"  # Update with your model's path
model = load_model(model_path)

# Define class labels
class_labels = {
    0: 'airplane',
    1: 'automobile',
    2: 'bird',
    3: 'cat',
    4: 'deer',
    5: 'dog',
    6: 'frog',
    7: 'horse',
    8: 'ship',
    9: 'truck'
}

# Function to classify images
def classify_image(image):
    # Preprocess the image
    image = image.resize((32, 32))  # Resize to match your model's input size
    image = np.array(image)
    image = image.astype('float32') / 255.0
    image = np.expand_dims(image, axis=0)

    # Get the predicted class probabilities
    predictions = model.predict(image)
    predicted_class_probs = predictions[0]

    # Prepare label and probability information
    label_probs = []
    high_prob_found = False
    for idx, prob in enumerate(predicted_class_probs):
        if prob >= 0.3:
            label_name = class_labels[idx]
            if prob > 0.6:  # Highlight high-probability labels
                label_name = f"<span style='color:black; background-color:#FFD700'>{label_name}</span>"
                high_prob_found = True
            label_probs.append(f"{label_name}: {prob:.4f}")

    # If no high probability label found, show "Not in data label"
    if not high_prob_found:
        label_probs = ["Not in data label"]

    # Return the class labels and their probabilities
    return "<br>".join(label_probs)

# Define the Gradio interface
iface = gr.Interface(
    fn=classify_image,
    # Access Image directly from gr
    inputs=gr.Image(type="pil"),
    # Access HTML directly from gr
    outputs=gr.HTML(),  # Use HTML output for custom font colors
    live=True,
    title="Image Classification with CNN",
    description=f"Available data labels: {', '.join(class_labels.values())}"
)

# Launch the interface
iface.launch()

# Launch the interface
iface.launch(share=True)

